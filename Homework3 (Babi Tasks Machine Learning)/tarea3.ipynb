{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3 - BaBi Tasks\n",
    "* Autor: Luis Miguel Fros\n",
    "* Numero de alumno: 15209822\n",
    "* Correo: lmfros@uc.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { height:200% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from math import floor\n",
    "from ipy_table import *\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "\n",
    "display(HTML(\"<style>.container { height:200% !important;}</style>\"))\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='floating_sidebar' style='position:fixed;left: 0;top: 100px;'}> <ul>              <li><a href='#notebook-container'>Introduccion</a></li>              <li><a href='#second-bullet'>SVM (Inicio)</a></li>              <ul>                  <li><a href='#comentario_cSVM'>Comentario sobre C</a></li>              </ul>              <li><a href='#third-bullet'>SVM (Tabla Resultados)</a></li>              <li><a href='#zeroth-bullet'>NN (Inicio)</a></li>              <li><a href='#second-bullet'>NN (Tabla Resultados)</a></li>              <li><a href='#fourth-bullet'>Resultados Comparativos</a></li>           </ul> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nav_info=\" <ul>\\\n",
    "              <li><a href='#notebook-container'>Introduccion</a></li>\\\n",
    "              <li><a href='#second-bullet'>SVM (Inicio)</a></li>\\\n",
    "              <ul>\\\n",
    "                  <li><a href='#comentario_cSVM'>Comentario sobre C</a></li>\\\n",
    "              </ul>\\\n",
    "              <li><a href='#third-bullet'>SVM (Tabla Resultados)</a></li>\\\n",
    "              <li><a href='#zeroth-bullet'>NN (Inicio)</a></li>\\\n",
    "              <li><a href='#second-bullet'>NN (Tabla Resultados)</a></li>\\\n",
    "              <li><a href='#fourth-bullet'>Resultados Comparativos</a></li>\\\n",
    "           </ul> \"\n",
    "display(HTML(\"<div id='floating_sidebar' style='position:fixed;left: 0;top: 100px;'}>\"+nav_info+\"</div>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentarios al corrector:\n",
    "* Como se puede ver en el bloque anterior, utilize una tabla de contenidos para facilitar la correcion.\n",
    "* Para poder ver la tabla de resultados de Neural Networks es necesario subir un poco despues hacer click al link.\n",
    "* En la ejecuccion de SVM , se ignora el Warning ConvergenceWarning porque el output queda muy grande. Este se tomo en cuenta en la etapa de testeo para dar un maximo de iteraciones de 10.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER=RegexpTokenizer(r'([a-zA-Z]+|\\?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_,stop_words):\n",
    "    ## recibe un string, y retorna una lista con los tokens que le pertenece\n",
    "    tokens=TOKENIZER.tokenize(input_)\n",
    "    stemmer = PorterStemmer()\n",
    "    st=stemmer.stem\n",
    "    \n",
    "    ### Se hace stemming y se remueven los stopwords\n",
    "    lowered_tokens=[st(token.lower()) for token in tokens if token not in stop_words]\n",
    "    return lowered_tokens\n",
    "\n",
    "def parse_stories(story):\n",
    "    substories=[]\n",
    "    stop_words=[]\n",
    "    # stop_words=set(stopwords.words('english'))\n",
    "    for line in story:\n",
    "        line_id,statement=line.split(\" \",maxsplit=1)\n",
    "        if line_id==\"1\":\n",
    "            substory=[]\n",
    "        if \"\\t\" in statement:\n",
    "            ## maneajr Q and Answer\n",
    "            query,answer,_=statement.split(\"\\t\")\n",
    "            query=tokenize(query,stop_words)\n",
    "            ## hacemos una copia de la lista porque es mutable\n",
    "            substories.append((substory[:],query,answer))\n",
    "        else:\n",
    "            ## manejar un fact\n",
    "            statement=tokenize(statement,stop_words)\n",
    "            substory.append(statement)\n",
    "    return substories\n",
    "\n",
    "def get_max_substory_length(stories):\n",
    "    # for i in stories:\n",
    "    #     print(i)\n",
    "    #     print(type(i))\n",
    "\n",
    "    substories_lenght=[len(substory) for substory,_,_ in stories]\n",
    "    return max(substories_lenght)\n",
    "\n",
    "PAD_TOKEN=\"_PAD\"\n",
    "def pad_substories(stories,max_lenght):\n",
    "    for substory,_,_ in stories:\n",
    "        for _ in  range(max_lenght-len(substory)):\n",
    "            substory.append([PAD_TOKEN])\n",
    "    return stories\n",
    "## n tamano del vocavu\n",
    "\n",
    "def get_vocabs(stories):\n",
    "    stories_tokens=[]\n",
    "    answers_tokens=[]\n",
    "    for substory,query,answer in stories:\n",
    "        stories_tokens +=[token for fact in substory for token in fact]\n",
    "        stories_tokens +=[token for token in query]\n",
    "        answers_tokens +=[answer]\n",
    "    stories_vocab=sorted(set(stories_tokens))\n",
    "    answers_vocab=sorted(set(answers_tokens))\n",
    "    stories_token_map={token: i for i,token in enumerate(stories_vocab)}\n",
    "    answers_token_map={token: i for i,token in enumerate(answers_vocab)}\n",
    "    return stories_vocab, stories_token_map, answers_vocab, answers_token_map\n",
    "\n",
    "def one_hot_vector(i,dim):\n",
    "    vector=np.zeros(dim) ## vector de puros zeors *dim\n",
    "    vector[i]=1\n",
    "    return vector\n",
    "\n",
    "def one_hot_encode(stories,stories_token_map,answers_token_map):\n",
    "    stories_encoded=[]\n",
    "    stories_vocab_size=len(stories_token_map)\n",
    "    # answers_vocab_size=len(answers_token_map)\n",
    "    for substory,query,answer in stories:\n",
    "        statements_encoded=[]\n",
    "        for statement in substory:\n",
    "            tokens_encoded=[one_hot_vector(stories_token_map[token],stories_vocab_size) for token in statement]\n",
    "            ## ahora la suma de bag of words\n",
    "            statements_encoded.append(sum(tokens_encoded))\n",
    "        question_encoded=(sum([one_hot_vector(stories_token_map[token],stories_vocab_size) for token in query]))\n",
    "        statements_encoded.append(question_encoded) ## agregarle la pregunta al final de los statements\n",
    "        answer_encoded=answers_token_map[answer]\n",
    "        ## statmens encoded es una lista de vecotres, np. conactenate apila los vectores\n",
    "        stories_encoded.append((np.concatenate(statements_encoded),answer_encoded))\n",
    "    return stories_encoded\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_classifier(clf,test_stores,test_answers,target_names):\n",
    "    test_predicted=clf.predict(test_stores)\n",
    "    ## (respuestas reales\n",
    "    accuracy=accuracy_score(test_answers,test_predicted)\n",
    "    conf_matr=confusion_matrix(test_answers,test_predicted)\n",
    "    print(classification_report(test_answers,test_predicted,labels=clf.classes_,target_names=target_names))\n",
    "    print(conf_matr)\n",
    "    print(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qa(DATASET_PATH=\"IIC2613_Course\\en\\qa6_yes-no-questions\",other=False):\n",
    "    if other:\n",
    "        lista_dir=os.listdir(\"D:/IA Github/IIC2613_Course/en/\")\n",
    "        train_stories=[]\n",
    "        test_stories=[]\n",
    "        for el in lista_dir:\n",
    "            if \"qa\" in el and \"train\" in el:\n",
    "                with open(\"IIC2613_Course\\en\\{}\".format(el)) as file:\n",
    "                    train_stories+=parse_stories(file.readlines())\n",
    "            elif \"qa\" in el and \"test\" in el:\n",
    "                with open(\"IIC2613_Course\\en\\{}\".format(el)) as file:\n",
    "                    test_stories+=parse_stories(file.readlines())\n",
    "        test_stories=np.array(test_stories)\n",
    "        train_stories=np.array(train_stories)\n",
    "    else:     \n",
    "        with open(DATASET_PATH+\"_train.txt\") as train_file:\n",
    "            train_stories=parse_stories(train_file.readlines())\n",
    "        with open(DATASET_PATH+\"_test.txt\") as test_file:\n",
    "            test_stories=parse_stories(test_file.readlines())\n",
    "    max_substory_length=get_max_substory_length(np.concatenate((train_stories,test_stories)))\n",
    "    padded_train_stories=pad_substories(train_stories,max_substory_length)\n",
    "    padded_test_stories=pad_substories(test_stories,max_substory_length)\n",
    "    stories_vocab,stories_token_map,answers_vocab,answers_token_map=get_vocabs(padded_train_stories+padded_test_stories)\n",
    "    encoded_train_stories=one_hot_encode(padded_train_stories,stories_token_map,answers_token_map)\n",
    "    encoded_test_stories=one_hot_encode(padded_test_stories,stories_token_map,answers_token_map)\n",
    "    stories_vocab_size=len(stories_vocab)\n",
    "    answers_vocab_size=len(answers_vocab)\n",
    "    feature_space_size=len(encoded_train_stories[0][0])\n",
    "    return encoded_train_stories,encoded_test_stories,stories_token_map,answers_token_map,max_substory_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a class=\"anchor\" id=\"comentario_nn\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<a class=\"anchor\" id=\"comentario_nn\"></a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " def multiple_nn(train_stories,train_answers,test_stories,test_answers):\n",
    "    results=[]\n",
    "    hidden_layer_mean=floor((len(train_stories)+len(train_answers))/2) ## hidden layer es mean of input/output layer\n",
    "    out_four_step=floor((hidden_layer_mean)/8)\n",
    "    for number_atributes in range(out_four_step,hidden_layer_mean,out_four_step):\n",
    "        clf = MLPClassifier(max_iter=100,solver='sgd',hidden_layer_sizes=(number_atributes,), random_state=2018,learning_rate=\"adaptive\") #random state = seed\n",
    "        clf.fit(train_stories,train_answers)\n",
    "        \n",
    "        train_predicted=clf.predict(train_stories)\n",
    "        ## (respuestas reales\n",
    "        accuracy_t=accuracy_score(train_answers,train_predicted)\n",
    "\n",
    "\n",
    "        test_predicted=clf.predict(test_stories)\n",
    "        ## (respuestas reales\n",
    "\n",
    "        accuracy=accuracy_score(test_answers,test_predicted)\n",
    "        results.append((accuracy,number_atributes,clf))\n",
    "\n",
    "    return max(results,key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_svm(train_stories,train_answers,test_stories,test_answers):\n",
    "    negative_exp=[-i for i in range(1,6)] ## -5 \n",
    "    positive_exp=[i for i in range(6,16)]\n",
    "    results=[]\n",
    "    for i in range(len(negative_exp)):  \n",
    "        c=2**negative_exp[i]\n",
    "        svm2=LinearSVC(\n",
    "            penalty=\"l2\",\n",
    "            loss=\"squared_hinge\",\n",
    "            C=c,\n",
    "            max_iter=10000\n",
    "        )\n",
    "        svm2.fit(train_stories,train_answers)\n",
    "\n",
    "        train_predicted=svm2.predict(train_stories)\n",
    "        ## (respuestas reales\n",
    "        accuracy_t=accuracy_score(train_answers,train_predicted)\n",
    "\n",
    "\n",
    "        test_predicted=svm2.predict(test_stories)\n",
    "        ## (respuestas reales\n",
    "        accuracy=accuracy_score(test_answers,test_predicted)\n",
    "        results.append((abs(accuracy-accuracy_t),negative_exp[i],svm2))\n",
    "\n",
    "    for i in range(len(positive_exp)):  \n",
    "        svm=LinearSVC(\n",
    "            penalty=\"l2\",\n",
    "            loss=\"squared_hinge\",\n",
    "            C=2**positive_exp[i],\n",
    "            max_iter=10000\n",
    "        )\n",
    "        svm.fit(train_stories,train_answers)\n",
    "\n",
    "        train_predicted=svm.predict(train_stories)\n",
    "        ## (respuestas reales\n",
    "        accuracy_t=accuracy_score(train_answers,train_predicted)\n",
    "\n",
    "        test_predicted=svm.predict(test_stories)\n",
    "        ## (respuestas reales\n",
    "        accuracy=accuracy_score(test_answers,test_predicted)\n",
    "        results.append((abs(accuracy-accuracy_t),positive_exp[i],svm))\n",
    "    return max(results,key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a class=\"anchor\" id=\"comentario_cSVM\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<a class=\"anchor\" id=\"comentario_cSVM\"></a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* $C$ es la constante de penalizacion asociada a las variables slack.\n",
    "* Mientras mayor es $C$, menor es la susceptibilidad a clases mal clasificadas.\n",
    "* Realizando pruebas empricas de $C \\in [{2^{-5},2^{-4},...,2^{16}}]$ obtuve los resultados presentados en la Figura 1 .\n",
    "* En la parte a) el criterio de elección de un $C$ para esta tabla, fue de maximizar el Test Accuracy.\n",
    "* Para ciertos valores de C, especialmente en el rango $[2^{-5},2^{-1}]$, el modelo SVM levantaba un aviso que no tenia suficientes iteraciones para converger en un hiper-plano. Por lo tanto se aumento el numero iteraciones máximas a 2000.\n",
    "* Podemos ver que los valores de $C$ cambiaron significativamente con respecto a la parte a) y b) .$67\\%$ de los Tasks aumentaron su constante por un factor de por lo menos 2. Por lo tanto, la mayoría disminuyo el sobre-ajuste al aumentar $C$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_svm():\n",
    "    lista_dir=os.listdir(\"D:/IA Github/IIC2613_Course/en/\")\n",
    "#     lista_dir=[\"qa20_agents-motivations_train.txt\"]\n",
    "    train_stories=[]\n",
    "    test_stories=[]\n",
    "    statistics={}\n",
    "    for el in lista_dir:\n",
    "        if \"qa\" in el and \"train\" in el:\n",
    "            official=el\n",
    "            el=\"IIC2613_Course\\en\\{}\".format(el.replace(\"_train.txt\",\"\"))\n",
    "            train_split,test_split,stories_token_map,answers_token_map,number_atributes=load_qa(el,False)\n",
    "            train_stories,train_answers=zip(*train_split)\n",
    "            test_stories,test_answers=zip(*test_split)\n",
    "            best_svm=multiple_svm(train_stories,train_answers,test_stories,test_answers)\n",
    "            # svm=LinearSVC(\n",
    "                # penalty=\"l2\",\n",
    "                # loss=\"squared_hinge\",\n",
    "                # C=1\n",
    "            # )\n",
    "            # svm.fit(train_stories,train_answers)\n",
    "            print(best_svm)\n",
    "            svm=best_svm[2]\n",
    "            print(\"Evaluar sobre el split de training\")\n",
    "            train_ac=evaluate_classifier(svm,train_stories,train_answers,answers_token_map.keys())\n",
    "\n",
    "            print(\"Evaluar sobre el split de testing\")\n",
    "            test_ac=evaluate_classifier(svm,test_stories,test_answers,answers_token_map.keys())\n",
    "            qa_string=official.split(\"_\")[0]\n",
    "            number_qa=int(qa_string.split(\"qa\")[-1])\n",
    "            statistics[number_qa]={\"C\":svm.C,\"test_accuracy\":test_ac,\"train_accuracy\":train_ac}\n",
    "    return statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_nn():\n",
    "    lista_dir=os.listdir(\"D:/IA Github/IIC2613_Course/en/\")\n",
    "    # lista_dir=[\"qa20_agents-motivations_train.txt\"]\n",
    "    train_stories=[]\n",
    "    test_stories=[]\n",
    "    statistics={}\n",
    "    for el in lista_dir:\n",
    "        if \"qa\" in el and \"train\" in el:\n",
    "            number_qa=int(qa_string.split(\"qa\")[-1])\n",
    "            print(\"-----Task {}-----\".format(number_qa))\n",
    "            official=el\n",
    "            el=\"IIC2613_Course\\en\\{}\".format(el.replace(\"_train.txt\",\"\"))\n",
    "            # el=\"{}\".format(el.replace(\"_train.txt\",\"\"))\n",
    "\n",
    "            train_split,test_split,stories_token_map,answers_token_map,number_atributes=load_qa(el,False)\n",
    "            train_stories,train_answers=zip(*train_split)\n",
    "            test_stories,test_answers=zip(*test_split)\n",
    "            best=multiple_nn(train_stories,train_answers,test_stories,test_answers)\n",
    "            print(best)\n",
    "            clf=best[-1]\n",
    "            clf.fit(train_stories,train_answers)\n",
    "\n",
    "            print(\"Evaluar sobre el split de training\")\n",
    "            train_ac=evaluate_classifier(clf,train_stories,train_answers,answers_token_map.keys())\n",
    "\n",
    "            print(\"Evaluar sobre el split de testing\")\n",
    "            test_ac=evaluate_classifier(clf,test_stories,test_answers,answers_token_map.keys())\n",
    "            qa_string=official.split(\"_\")[0]\n",
    "            number_qa=int(qa_string.split(\"qa\")[-1])\n",
    "            print(test_ac,train_ac)\n",
    "            statistics[number_qa]={\"Size\":best[1],\"test_accuracy\":test_ac,\"train_accuracy\":train_ac}\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a class=\"anchor\" id=\"zeroth-bullet\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<a class=\"anchor\" id=\"zeroth-bullet\"></a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.48099999999999998, 500, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(500,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.00      0.00      0.00       122\n",
      "         yes       0.57      0.78      0.66       466\n",
      "       maybe       0.65      0.57      0.61       412\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      1000\n",
      "   macro avg       0.40      0.45      0.42      1000\n",
      "weighted avg       0.53      0.60      0.55      1000\n",
      "\n",
      "[[  0  99  23]\n",
      " [  0 362 104]\n",
      " [  0 178 234]]\n",
      "0.596\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.00      0.00      0.00       150\n",
      "         yes       0.46      0.68      0.55       437\n",
      "       maybe       0.52      0.44      0.48       413\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      1000\n",
      "   macro avg       0.33      0.37      0.34      1000\n",
      "weighted avg       0.42      0.48      0.44      1000\n",
      "\n",
      "[[  0 116  34]\n",
      " [  1 299 137]\n",
      " [  1 230 182]]\n",
      "0.481\n",
      "0.481 0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.44700000000000001, 625, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(625,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.69      0.45      0.55       147\n",
      "      garden       0.56      0.70      0.62       183\n",
      "    bathroom       0.63      0.54      0.58       153\n",
      "     kitchen       0.49      0.69      0.57       196\n",
      "     hallway       0.68      0.47      0.56       158\n",
      "     bedroom       0.59      0.56      0.58       163\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      1000\n",
      "   macro avg       0.61      0.57      0.58      1000\n",
      "weighted avg       0.60      0.58      0.58      1000\n",
      "\n",
      "[[ 66  26  11  25   7  12]\n",
      " [  3 129  12  21   7  11]\n",
      " [  5  24  83  24   4  13]\n",
      " [  7  20  10 135   8  16]\n",
      " [ 10  10   8  43  75  12]\n",
      " [  4  21   8  28  10  92]]\n",
      "0.58\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.47      0.30      0.37       153\n",
      "      garden       0.46      0.53      0.49       171\n",
      "    bathroom       0.45      0.45      0.45       164\n",
      "     kitchen       0.40      0.55      0.46       187\n",
      "     hallway       0.52      0.38      0.44       170\n",
      "     bedroom       0.44      0.44      0.44       155\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1000\n",
      "   macro avg       0.46      0.44      0.44      1000\n",
      "weighted avg       0.45      0.45      0.44      1000\n",
      "\n",
      "[[ 46  15  25  31  12  24]\n",
      " [  6  91  10  27  21  16]\n",
      " [ 13  23  74  27  15  12]\n",
      " [ 16  20  18 103   8  22]\n",
      " [  9  25  18  42  65  11]\n",
      " [  8  25  21  29   4  68]]\n",
      "0.447\n",
      "0.447 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.28299999999999997, 750, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(750,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.45      0.44      0.44       164\n",
      "      garden       0.46      0.25      0.32       157\n",
      "    bathroom       0.37      0.62      0.46       182\n",
      "     kitchen       0.47      0.38      0.42       160\n",
      "     hallway       0.40      0.31      0.35       160\n",
      "     bedroom       0.48      0.54      0.51       177\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      1000\n",
      "   macro avg       0.44      0.42      0.42      1000\n",
      "weighted avg       0.44      0.43      0.42      1000\n",
      "\n",
      "[[ 72   6  42   8  16  20]\n",
      " [ 21  39  34  17  14  32]\n",
      " [ 17  11 112  14  14  14]\n",
      " [ 17  13  35  61  16  18]\n",
      " [ 18   7  50  15  50  20]\n",
      " [ 16   8  30  14  14  95]]\n",
      "0.429\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.31      0.33      0.32       179\n",
      "      garden       0.30      0.17      0.22       163\n",
      "    bathroom       0.25      0.51      0.34       152\n",
      "     kitchen       0.36      0.21      0.27       189\n",
      "     hallway       0.27      0.18      0.21       169\n",
      "     bedroom       0.27      0.33      0.30       148\n",
      "\n",
      "   micro avg       0.28      0.28      0.28      1000\n",
      "   macro avg       0.29      0.29      0.27      1000\n",
      "weighted avg       0.29      0.28      0.27      1000\n",
      "\n",
      "[[59 19 46 19 14 22]\n",
      " [23 28 57 14  9 32]\n",
      " [26  5 77 12 15 17]\n",
      " [34 16 39 40 27 33]\n",
      " [25 10 55 18 30 31]\n",
      " [26 16 33  7 17 49]]\n",
      "0.283\n",
      "0.283 0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.441, 750, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(750,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.69      0.59      0.64       163\n",
      "      garden       0.62      0.58      0.60       158\n",
      "    bathroom       0.76      0.57      0.65       152\n",
      "     kitchen       0.51      0.82      0.63       200\n",
      "     hallway       0.67      0.62      0.65       163\n",
      "     bedroom       0.65      0.52      0.58       164\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.65      0.61      0.62      1000\n",
      "weighted avg       0.65      0.62      0.62      1000\n",
      "\n",
      "[[ 96   9   7  36   7   8]\n",
      " [  8  91   5  34   9  11]\n",
      " [  8  13  86  27   9   9]\n",
      " [  7  13   5 164   7   4]\n",
      " [ 10  13   1  25 101  13]\n",
      " [ 10   8   9  35  17  85]]\n",
      "0.623\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.48      0.34      0.40       172\n",
      "      garden       0.53      0.34      0.41       183\n",
      "    bathroom       0.57      0.40      0.47       179\n",
      "     kitchen       0.37      0.75      0.50       154\n",
      "     hallway       0.43      0.48      0.45       153\n",
      "     bedroom       0.38      0.38      0.38       159\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      1000\n",
      "   macro avg       0.46      0.45      0.44      1000\n",
      "weighted avg       0.47      0.44      0.44      1000\n",
      "\n",
      "[[ 58  14   8  57  14  21]\n",
      " [ 15  62  19  32  24  31]\n",
      " [ 14   9  72  42  20  22]\n",
      " [  8   8   7 115  13   3]\n",
      " [ 13  10   8  28  73  21]\n",
      " [ 13  13  13  33  26  61]]\n",
      "0.441\n",
      "0.441 0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.27000000000000002, 750, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(750,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        park       0.50      0.50      0.50       178\n",
      "      office       0.51      0.47      0.49       159\n",
      "      school       0.52      0.64      0.57       173\n",
      "      cinema       0.49      0.55      0.52       172\n",
      "     kitchen       0.52      0.57      0.54       169\n",
      "     bedroom       0.60      0.35      0.44       149\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1000\n",
      "   macro avg       0.52      0.51      0.51      1000\n",
      "weighted avg       0.52      0.52      0.51      1000\n",
      "\n",
      "[[ 89  16  21  21  19  12]\n",
      " [ 17  74  15  23  23   7]\n",
      " [ 12  13 110  14  17   7]\n",
      " [ 18  16  22  94  17   5]\n",
      " [ 20  14  17  19  96   3]\n",
      " [ 23  11  28  22  13  52]]\n",
      "0.515\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        park       0.28      0.33      0.30       162\n",
      "      office       0.26      0.30      0.28       171\n",
      "      school       0.24      0.27      0.25       176\n",
      "      cinema       0.29      0.31      0.30       177\n",
      "     kitchen       0.27      0.28      0.27       152\n",
      "     bedroom       0.33      0.12      0.18       162\n",
      "\n",
      "   micro avg       0.27      0.27      0.27      1000\n",
      "   macro avg       0.28      0.27      0.26      1000\n",
      "weighted avg       0.28      0.27      0.26      1000\n",
      "\n",
      "[[53 26 29 21 21 12]\n",
      " [31 52 25 22 33  8]\n",
      " [31 37 47 30 22  9]\n",
      " [24 36 29 55 27  6]\n",
      " [22 26 25 31 43  5]\n",
      " [29 25 39 33 16 20]]\n",
      "0.27\n",
      "0.27 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.39300000000000002, 500, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(500,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       mouse       0.54      0.68      0.60       290\n",
      "       sheep       0.60      0.61      0.60       252\n",
      "         cat       0.55      0.51      0.53       242\n",
      "        wolf       0.63      0.44      0.51       216\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      1000\n",
      "   macro avg       0.58      0.56      0.56      1000\n",
      "weighted avg       0.57      0.57      0.57      1000\n",
      "\n",
      "[[197  41  36  16]\n",
      " [ 47 154  31  20]\n",
      " [ 68  30 124  20]\n",
      " [ 55  33  34  94]]\n",
      "0.569\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       mouse       0.31      0.47      0.37       213\n",
      "       sheep       0.41      0.50      0.45       239\n",
      "         cat       0.35      0.33      0.34       207\n",
      "        wolf       0.57      0.30      0.40       341\n",
      "\n",
      "   micro avg       0.39      0.39      0.39      1000\n",
      "   macro avg       0.41      0.40      0.39      1000\n",
      "weighted avg       0.43      0.39      0.39      1000\n",
      "\n",
      "[[101  40  31  41]\n",
      " [ 66 120  37  16]\n",
      " [ 60  56  68  23]\n",
      " [ 99  78  60 104]]\n",
      "0.393\n",
      "0.393 0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.46800000000000003, 625, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(625,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gray       0.53      0.43      0.47       226\n",
      "       green       0.57      0.56      0.56       247\n",
      "       white       0.54      0.47      0.50       247\n",
      "      yellow       0.54      0.68      0.60       280\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1000\n",
      "   macro avg       0.54      0.54      0.53      1000\n",
      "weighted avg       0.54      0.54      0.54      1000\n",
      "\n",
      "[[ 97  33  35  61]\n",
      " [ 23 139  38  47]\n",
      " [ 30  45 117  55]\n",
      " [ 34  29  28 189]]\n",
      "0.542\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gray       0.53      0.40      0.46       251\n",
      "       green       0.50      0.44      0.47       257\n",
      "       white       0.46      0.43      0.45       256\n",
      "      yellow       0.42      0.61      0.49       236\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      1000\n",
      "   macro avg       0.48      0.47      0.47      1000\n",
      "weighted avg       0.48      0.47      0.47      1000\n",
      "\n",
      "[[101  37  44  69]\n",
      " [ 37 113  47  60]\n",
      " [ 34  41 111  70]\n",
      " [ 18  37  38 143]]\n",
      "0.468\n",
      "0.468 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52000000000000002, 875, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(875,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.59      0.55      0.57       495\n",
      "          no       0.59      0.64      0.61       505\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      1000\n",
      "   macro avg       0.59      0.59      0.59      1000\n",
      "weighted avg       0.59      0.59      0.59      1000\n",
      "\n",
      "[[270 225]\n",
      " [184 321]]\n",
      "0.591\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.50      0.47      0.48       480\n",
      "          no       0.54      0.57      0.55       520\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1000\n",
      "   macro avg       0.52      0.52      0.52      1000\n",
      "weighted avg       0.52      0.52      0.52      1000\n",
      "\n",
      "[[225 255]\n",
      " [225 295]]\n",
      "0.52\n",
      "0.52 0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52100000000000002, 500, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(500,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.65      0.59      0.62       495\n",
      "          no       0.63      0.69      0.66       505\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1000\n",
      "   macro avg       0.64      0.64      0.64      1000\n",
      "weighted avg       0.64      0.64      0.64      1000\n",
      "\n",
      "[[292 203]\n",
      " [158 347]]\n",
      "0.639\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.55      0.54      0.55       531\n",
      "          no       0.49      0.50      0.49       469\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1000\n",
      "   macro avg       0.52      0.52      0.52      1000\n",
      "weighted avg       0.52      0.52      0.52      1000\n",
      "\n",
      "[[287 244]\n",
      " [235 234]]\n",
      "0.521\n",
      "0.521 0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.10299999999999999, 500, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(500,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         w,w       0.20      0.42      0.27        92\n",
      "         s,w       0.14      0.22      0.17        91\n",
      "         n,w       0.18      0.14      0.16        85\n",
      "         e,n       0.15      0.08      0.10        79\n",
      "         w,n       0.19      0.24      0.21        85\n",
      "         e,e       0.20      0.21      0.20        86\n",
      "         s,e       0.21      0.19      0.20        83\n",
      "         e,s       0.22      0.24      0.23        79\n",
      "         n,n       0.16      0.10      0.12        87\n",
      "         n,e       0.00      0.00      0.00        70\n",
      "         s,s       0.22      0.21      0.22        84\n",
      "         w,s       0.22      0.14      0.17        79\n",
      "\n",
      "   micro avg       0.19      0.19      0.19      1000\n",
      "   macro avg       0.17      0.18      0.17      1000\n",
      "weighted avg       0.17      0.19      0.17      1000\n",
      "\n",
      "[[39 12  4  2  6  9  3  5  4  0  2  6]\n",
      " [20 20  7  2 10  3  6  9  3  0  6  5]\n",
      " [14 12 12  2  9 10  4  5  5  0  6  6]\n",
      " [14 13  4  6  7 10  4  6  4  0  7  4]\n",
      " [12 12  5  1 20  6  7  6  7  0  6  3]\n",
      " [13  8  3  6  6 18  9  9  4  0  7  3]\n",
      " [20  7  9  7  7  3 16  5  4  0  2  3]\n",
      " [ 9 10  8  0  8  5  5 19  5  0  8  2]\n",
      " [14 10  6  4  8  7  7  5  9  1 13  3]\n",
      " [18 13  2  4  7  4  7  4  3  0  4  4]\n",
      " [ 9 14  5  4 10  7  5  7  4  0 18  1]\n",
      " [15  8  3  3  7 10  4  8  6  2  2 11]]\n",
      "0.188\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         w,w       0.08      0.19      0.12        81\n",
      "         s,w       0.12      0.16      0.14        88\n",
      "         n,w       0.11      0.10      0.10        79\n",
      "         e,n       0.10      0.05      0.06        85\n",
      "         w,n       0.12      0.15      0.13        92\n",
      "         e,e       0.14      0.13      0.14        92\n",
      "         s,e       0.07      0.06      0.07        83\n",
      "         e,s       0.07      0.10      0.08        71\n",
      "         n,n       0.11      0.09      0.10        93\n",
      "         n,e       0.00      0.00      0.00        80\n",
      "         s,s       0.12      0.12      0.12        90\n",
      "         w,s       0.11      0.08      0.09        66\n",
      "\n",
      "   micro avg       0.10      0.10      0.10      1000\n",
      "   macro avg       0.10      0.10      0.10      1000\n",
      "weighted avg       0.10      0.10      0.10      1000\n",
      "\n",
      "[[15 11 10  2  7 12  6  2  6  0  5  5]\n",
      " [18 14  7  2 11  7  5  8  8  1  4  3]\n",
      " [20 11  8  4  6  4  5  8  6  0  5  2]\n",
      " [10 12  4  4  5  7 10  7 11  0 12  3]\n",
      " [13 13  6  3 14  6  6  8  8  0  8  7]\n",
      " [16  3  7  3 15 12 10 10  4  1  7  4]\n",
      " [21  7  6  1  9  5  5 10  6  0  9  4]\n",
      " [ 9  8  2  5 13  3  7  7  6  0 10  1]\n",
      " [18 14  8  4 10  7  4 11  8  1  5  3]\n",
      " [15  2  5  4 12 10  5 10  3  0 10  4]\n",
      " [16 15  5  6  9  6  4  8  5  0 11  5]\n",
      " [ 7  9  6  3  9  4  2 12  2  1  6  5]]\n",
      "0.103\n",
      "0.103 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.29699999999999999, 875, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(875,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.58      0.36      0.45       154\n",
      "      garden       0.58      0.43      0.49       155\n",
      "    bathroom       0.47      0.53      0.49       177\n",
      "     kitchen       0.45      0.63      0.52       175\n",
      "     hallway       0.45      0.47      0.46       173\n",
      "     bedroom       0.52      0.49      0.50       166\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      1000\n",
      "   macro avg       0.51      0.49      0.49      1000\n",
      "weighted avg       0.50      0.49      0.49      1000\n",
      "\n",
      "[[ 56   6  11  40  24  17]\n",
      " [  9  66  26  18  25  11]\n",
      " [  8  12  93  23  25  16]\n",
      " [  6   7  22 111  12  17]\n",
      " [  8  15  26  26  82  16]\n",
      " [  9   8  21  31  15  82]]\n",
      "0.49\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.17      0.11      0.13       149\n",
      "      garden       0.40      0.17      0.24       171\n",
      "    bathroom       0.38      0.47      0.42       187\n",
      "     kitchen       0.21      0.30      0.25       154\n",
      "     hallway       0.35      0.41      0.38       157\n",
      "     bedroom       0.28      0.29      0.29       182\n",
      "\n",
      "   micro avg       0.30      0.30      0.30      1000\n",
      "   macro avg       0.30      0.29      0.28      1000\n",
      "weighted avg       0.30      0.30      0.29      1000\n",
      "\n",
      "[[17  8 25 43 21 35]\n",
      " [17 29 35 30 34 26]\n",
      " [15 11 87 27 24 23]\n",
      " [19 10 32 46 17 30]\n",
      " [15  7 20 28 65 22]\n",
      " [20  8 28 47 26 53]]\n",
      "0.297\n",
      "0.297 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.67000000000000004, 875, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(875,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      garden       0.89      0.09      0.16        91\n",
      "       bored       0.89      0.99      0.93       164\n",
      "     thirsty       0.60      0.06      0.11        98\n",
      "     kitchen       0.82      0.75      0.78       151\n",
      "       tired       0.52      0.98      0.68       186\n",
      "      hungry       0.83      0.82      0.83       158\n",
      "     bedroom       0.96      0.96      0.96       152\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1000\n",
      "   macro avg       0.79      0.66      0.64      1000\n",
      "weighted avg       0.78      0.75      0.70      1000\n",
      "\n",
      "[[  8   0   1   0  82   0   0]\n",
      " [  0 162   0   0   0   0   2]\n",
      " [  1   2   6   0  89   0   0]\n",
      " [  0   8   0 113   0  26   4]\n",
      " [  0   1   3   0 182   0   0]\n",
      " [  0   5   0  23   0 130   0]\n",
      " [  0   5   0   1   0   0 146]]\n",
      "0.747\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      garden       0.33      0.02      0.04        97\n",
      "       bored       0.82      0.93      0.87       159\n",
      "     thirsty       0.12      0.01      0.02        94\n",
      "     kitchen       0.73      0.63      0.68       157\n",
      "       tired       0.48      0.95      0.64       180\n",
      "      hungry       0.69      0.69      0.69       152\n",
      "     bedroom       0.89      0.89      0.89       161\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      1000\n",
      "   macro avg       0.58      0.59      0.55      1000\n",
      "weighted avg       0.62      0.67      0.61      1000\n",
      "\n",
      "[[  2   0   2   0  93   0   0]\n",
      " [  0 148   0   0   0   4   7]\n",
      " [  2   0   1   0  91   0   0]\n",
      " [  0  10   0  99   0  40   8]\n",
      " [  2   2   5   0 171   0   0]\n",
      " [  0  13   0  31   0 105   3]\n",
      " [  0   8   0   5   0   4 144]]\n",
      "0.67\n",
      "0.67 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.20000000000000001, 750, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(750,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.70      0.51      0.59       145\n",
      "      garden       0.75      0.54      0.63       158\n",
      "    bathroom       0.55      0.82      0.66       210\n",
      "     kitchen       0.83      0.49      0.62       138\n",
      "     hallway       0.75      0.47      0.58       147\n",
      "     bedroom       0.55      0.79      0.65       202\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      1000\n",
      "   macro avg       0.69      0.60      0.62      1000\n",
      "weighted avg       0.67      0.63      0.62      1000\n",
      "\n",
      "[[ 74   7  28   5   4  27]\n",
      " [  6  86  33   0   2  31]\n",
      " [  8   4 172   4   6  16]\n",
      " [  7   6  22  68   6  29]\n",
      " [  7   8  31   3  69  29]\n",
      " [  4   3  28   2   5 160]]\n",
      "0.629\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.21      0.11      0.14       175\n",
      "      garden       0.22      0.12      0.15       167\n",
      "    bathroom       0.22      0.50      0.31       187\n",
      "     kitchen       0.21      0.08      0.12       160\n",
      "     hallway       0.21      0.06      0.09       165\n",
      "     bedroom       0.16      0.31      0.21       146\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      1000\n",
      "   macro avg       0.20      0.20      0.17      1000\n",
      "weighted avg       0.20      0.20      0.17      1000\n",
      "\n",
      "[[19 20 64 16  6 50]\n",
      " [19 20 72 11 10 35]\n",
      " [12 19 93  6 10 47]\n",
      " [10  8 70 13  3 56]\n",
      " [18 13 57 11 10 56]\n",
      " [13 13 60  6  9 45]]\n",
      "0.2\n",
      "0.2 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.183, 125, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(125,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.64      0.87      0.74       198\n",
      "      garden       0.77      0.62      0.69       144\n",
      "    bathroom       0.73      0.71      0.72       171\n",
      "     kitchen       0.75      0.73      0.74       183\n",
      "     hallway       0.76      0.71      0.73       146\n",
      "     bedroom       0.74      0.64      0.68       158\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      1000\n",
      "   macro avg       0.73      0.71      0.72      1000\n",
      "weighted avg       0.73      0.72      0.72      1000\n",
      "\n",
      "[[172   3   6   7   4   6]\n",
      " [ 21  89  14   6   5   9]\n",
      " [ 21   6 122  11   7   4]\n",
      " [ 15   4  10 134   8  12]\n",
      " [ 15   8   8   7 103   5]\n",
      " [ 23   5   7  14   8 101]]\n",
      "0.721\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.16      0.34      0.22       185\n",
      "      garden       0.17      0.06      0.09       154\n",
      "    bathroom       0.20      0.18      0.19       215\n",
      "     kitchen       0.28      0.26      0.27       167\n",
      "     hallway       0.14      0.08      0.10       146\n",
      "     bedroom       0.12      0.13      0.13       133\n",
      "\n",
      "   micro avg       0.18      0.18      0.18      1000\n",
      "   macro avg       0.18      0.17      0.17      1000\n",
      "weighted avg       0.18      0.18      0.17      1000\n",
      "\n",
      "[[62  9 40 29 18 27]\n",
      " [63  9 31 22  8 21]\n",
      " [89 13 39 18 17 39]\n",
      " [41 12 34 44 16 20]\n",
      " [73  5 20 24 12 12]\n",
      " [48  5 29 22 12 17]]\n",
      "0.183\n",
      "0.183 0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52600000000000002, 375, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(375,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.55      0.58      0.56       159\n",
      "      garden       0.54      0.38      0.45       160\n",
      "    bathroom       0.58      0.49      0.53       162\n",
      "     kitchen       0.52      0.57      0.54       169\n",
      "     hallway       0.50      0.65      0.57       180\n",
      "     bedroom       0.63      0.59      0.61       170\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      1000\n",
      "   macro avg       0.55      0.54      0.54      1000\n",
      "weighted avg       0.55      0.55      0.54      1000\n",
      "\n",
      "[[ 92  12   8  17  22   8]\n",
      " [ 16  61  17  27  21  18]\n",
      " [ 15  11  79  19  24  14]\n",
      " [ 19   9   8  97  29   7]\n",
      " [ 11  15  11  13 117  13]\n",
      " [ 15   6  14  14  20 101]]\n",
      "0.547\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      office       0.60      0.48      0.53       177\n",
      "      garden       0.55      0.46      0.50       156\n",
      "    bathroom       0.50      0.49      0.50       167\n",
      "     kitchen       0.47      0.57      0.51       176\n",
      "     hallway       0.50      0.61      0.55       171\n",
      "     bedroom       0.58      0.54      0.56       153\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      1000\n",
      "   macro avg       0.53      0.53      0.53      1000\n",
      "weighted avg       0.53      0.53      0.53      1000\n",
      "\n",
      "[[ 85  16  15  22  20  19]\n",
      " [ 13  71  20  19  22  11]\n",
      " [  9  11  82  30  22  13]\n",
      " [ 13  16  14 101  27   5]\n",
      " [  6   8  23  18 104  12]\n",
      " [ 16   6  10  27  11  83]]\n",
      "0.526\n",
      "0.526 0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.434, 750, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(750,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fred       0.74      0.65      0.69       151\n",
      "       apple       0.70      0.75      0.72       167\n",
      "    football       0.72      0.63      0.67       144\n",
      "        milk       0.66      0.74      0.70       171\n",
      "        Bill       0.89      0.93      0.91       136\n",
      "        Mary       0.84      0.95      0.89       136\n",
      "        Jeff       0.95      0.73      0.82        95\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1000\n",
      "   macro avg       0.78      0.77      0.77      1000\n",
      "weighted avg       0.77      0.77      0.76      1000\n",
      "\n",
      "[[ 98  17  14  21   0   1   0]\n",
      " [ 12 125   8  22   0   0   0]\n",
      " [ 14  15  91  23   0   0   1]\n",
      " [  9  21  14 127   0   0   0]\n",
      " [  0   0   0   0 127   7   2]\n",
      " [  0   0   0   0   6 129   1]\n",
      " [  0   0   0   0  10  16  69]]\n",
      "0.766\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fred       0.33      0.24      0.28       164\n",
      "       apple       0.37      0.36      0.36       188\n",
      "    football       0.35      0.27      0.31       129\n",
      "        milk       0.39      0.54      0.45       189\n",
      "        Bill       0.61      0.69      0.64       137\n",
      "        Mary       0.49      0.73      0.58        95\n",
      "        Jeff       0.76      0.27      0.39        98\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      1000\n",
      "   macro avg       0.47      0.44      0.43      1000\n",
      "weighted avg       0.45      0.43      0.42      1000\n",
      "\n",
      "[[ 40  40  21  62   1   0   0]\n",
      " [ 39  67  21  61   0   0   0]\n",
      " [ 21  32  35  41   0   0   0]\n",
      " [ 22  42  22 103   0   0   0]\n",
      " [  0   0   0   0  94  36   7]\n",
      " [  0   0   0   0  25  69   1]\n",
      " [  0   0   0   0  35  37  26]]\n",
      "0.434\n",
      "0.434 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52400000000000002, 875, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(875,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.63      0.56      0.59       492\n",
      "          no       0.62      0.69      0.65       508\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.63      0.62      0.62      1000\n",
      "weighted avg       0.62      0.62      0.62      1000\n",
      "\n",
      "[[275 217]\n",
      " [159 349]]\n",
      "0.624\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.53      0.44      0.48       503\n",
      "          no       0.52      0.61      0.56       497\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1000\n",
      "   macro avg       0.53      0.52      0.52      1000\n",
      "weighted avg       0.53      0.52      0.52      1000\n",
      "\n",
      "[[223 280]\n",
      " [196 301]]\n",
      "0.524\n",
      "0.524 0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.61899999999999999, 875, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(875,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.69      0.70      0.69       468\n",
      "       three       0.67      0.73      0.70       488\n",
      "         one       0.00      0.00      0.00         1\n",
      "         two       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1000\n",
      "   macro avg       0.34      0.36      0.35      1000\n",
      "weighted avg       0.65      0.68      0.66      1000\n",
      "\n",
      "[[326 142   0   0]\n",
      " [134 354   0   0]\n",
      " [  0   1   0   0]\n",
      " [ 15  28   0   0]]\n",
      "0.68\n",
      "Evaluar sobre el split de testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.61      0.60      0.61       468\n",
      "       three       0.62      0.70      0.66       488\n",
      "         one       0.00      0.00      0.00         2\n",
      "         two       0.00      0.00      0.00        42\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.31      0.32      0.32      1000\n",
      "weighted avg       0.59      0.62      0.60      1000\n",
      "\n",
      "[[279 189   0   0]\n",
      " [148 340   0   0]\n",
      " [  2   0   0   0]\n",
      " [ 25  17   0   0]]\n",
      "0.619\n",
      "0.619 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.435, 750, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(750,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluar sobre el split de training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1537: UserWarning: labels size, 13, does not match size of target_names, 14\n",
      "  .format(len(labels), len(target_names))\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           football       0.65      0.37      0.47       194\n",
      "apple,football,milk       0.00      0.00      0.00        10\n",
      "              apple       0.00      0.00      0.00         3\n",
      "football,apple,milk       0.00      0.00      0.00        22\n",
      "            nothing       0.00      0.00      0.00         2\n",
      "         apple,milk       0.68      0.41      0.51       188\n",
      "     apple,football       0.00      0.00      0.00        12\n",
      "      milk,football       0.00      0.00      0.00         9\n",
      "apple,milk,football       0.69      0.34      0.45       198\n",
      "         milk,apple       0.00      0.00      0.00         6\n",
      "milk,football,apple       0.00      0.00      0.00        11\n",
      "               milk       0.00      0.00      0.00         1\n",
      "     football,apple       0.45      0.90      0.60       344\n",
      "\n",
      "          micro avg       0.52      0.52      0.52      1000\n",
      "          macro avg       0.19      0.15      0.16      1000\n",
      "       weighted avg       0.55      0.52      0.48      1000\n",
      "\n",
      "[[ 71   0   0   0   0  11   0   0   4   0   0   0 108]\n",
      " [  1   0   0   0   0   1   0   0   0   0   0   0   8]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3]\n",
      " [  3   0   0   0   0   0   0   0   0   0   0   0  19]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2]\n",
      " [  9   0   0   0   0  77   0   0   4   0   0   0  98]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0  11]\n",
      " [  0   0   0   0   0   1   0   0   1   0   0   0   7]\n",
      " [ 11   0   0   0   0  12   0   0  67   0   0   0 108]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   0   4]\n",
      " [  0   0   0   0   0   2   0   0   4   0   0   0   5]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [ 14   0   0   0   0   8   0   0  14   0   0   0 308]]\n",
      "0.523\n",
      "Evaluar sobre el split de testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1537: UserWarning: labels size, 13, does not match size of target_names, 14\n",
      "  .format(len(labels), len(target_names))\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           football       0.52      0.24      0.33       204\n",
      "apple,football,milk       0.00      0.00      0.00        11\n",
      "              apple       0.00      0.00      0.00         1\n",
      "football,apple,milk       0.00      0.00      0.00        10\n",
      "            nothing       0.00      0.00      0.00         0\n",
      "         apple,milk       0.46      0.25      0.32       186\n",
      "     apple,football       0.00      0.00      0.00        18\n",
      "      milk,football       0.00      0.00      0.00         7\n",
      "apple,milk,football       0.57      0.20      0.30       207\n",
      "         milk,apple       0.00      0.00      0.00         9\n",
      "milk,football,apple       0.00      0.00      0.00        10\n",
      "               milk       0.00      0.00      0.00         0\n",
      "     football,apple       0.41      0.89      0.56       336\n",
      "\n",
      "          micro avg       0.43      0.44      0.44       999\n",
      "          macro avg       0.15      0.12      0.12       999\n",
      "       weighted avg       0.45      0.44      0.38       999\n",
      "\n",
      "[[ 49   0   0   0  12   0   0   0   7   0   0 136]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   9]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  1   0   0   0   1   0   0   0   2   0   0   6]\n",
      " [ 15   0   0   0  46   0   0   0   5   0   0 120]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0  17]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   7]\n",
      " [ 17   0   0   0  26   0   0   0  42   0   0 122]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   8]\n",
      " [  1   0   0   0   1   0   0   0   1   0   0   7]\n",
      " [ 12   0   0   0  10   0   0   0  16   0   0 298]]\n",
      "0.435\n",
      "0.435 0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.64200000000000002, 375, MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(375,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=2018, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.65      0.98      0.78       633\n",
      "          no       0.78      0.10      0.17       367\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      1000\n",
      "   macro avg       0.72      0.54      0.48      1000\n",
      "weighted avg       0.70      0.66      0.56      1000\n",
      "\n",
      "[[623  10]\n",
      " [332  35]]\n",
      "0.658\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.64      0.99      0.78       638\n",
      "          no       0.60      0.03      0.06       362\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1000\n",
      "   macro avg       0.62      0.51      0.42      1000\n",
      "weighted avg       0.63      0.64      0.52      1000\n",
      "\n",
      "[[630   8]\n",
      " [350  12]]\n",
      "0.642\n",
      "0.642 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" cellpadding=\"3\" cellspacing=\"0\"  style=\"border:black; border-collapse:collapse;\"><tr><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>Task</b></td><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>Hidden&nbsp;Layer&nbsp;Size</b></td><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>Train&nbsp;Accuracy</b></td><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>Test&nbsp;Accuracy</b></td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">1</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">875</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4900</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2970</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">2</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">750</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6290</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2000</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">3</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">125</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.7210</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.1830</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">4</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">375</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5470</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5260</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">5</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">750</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.7660</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4340</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">6</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">875</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6240</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5240</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">7</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">875</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6800</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6190</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">8</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">750</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5230</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4350</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">9</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">375</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6580</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6420</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">10</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">500</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5960</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4810</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">11</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">625</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5800</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4470</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">12</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">750</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4290</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2830</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">13</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">750</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6230</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4410</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">14</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">750</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5150</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2700</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">15</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">500</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5690</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.3930</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">16</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">625</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5420</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4680</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">17</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">875</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5910</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5200</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">18</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">500</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6390</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5210</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">19</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">500</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.1880</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.1030</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">20</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">875</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.7470</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6700</td></tr></table>"
      ],
      "text/plain": [
       "<ipy_table.ipy_table.IpyTable at 0x11e0de90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction=main_nn()\n",
    "lista=[[i,diction[i][\"Size\"],diction[i][\"train_accuracy\"],diction[i][\"test_accuracy\"]] for i in sorted(diction.keys())]\n",
    "make_table([[\"Task\",\"Hidden Layer Size\",\"Train Accuracy\",\"Test Accuracy\"]]+lista)\n",
    "apply_theme('basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para determinar el numero de capas se decidio limitar el numero de posibles combinaciones entre 8 valores.\n",
    "* $ Size \\in [mean(input\\_layer,output\\_layer),output\\_layer]$ , para obtener 8 valores en este rango se dividio uniformemente. [(codigo)](#comentario_nn)\n",
    "* La cantidad es acotada porque no tengo la capacidad computacional para poder probar empiricamente mas valores.\n",
    "* La condicion de termino para el aprendizaje es cuando llega a 100 iteraciones.\n",
    "* Las preciciones promedio son las que estan presentadas en la tabla.\n",
    "* Si observo sobre ajuste, especialmente en los Tasks $1,2,3$ donde la diferencia de precision entre el set de entrenamiento y el de test es mas que la mitad.\n",
    "* El Task que obtuvo mejor rendimiento fue el $20$ seguido por $9$. El task $20$ como es mencionado en los [resultados](#third-bullet) de la SVM, tiene el mismo impacto en este modelo. \n",
    "* El que obtuvo peor rendimiento fue el Task $19$ que es de busqueda, tambien como se menciono en los resultados de SVM, es un problema de busqueda y este modelo tampoco es bueno para resolver ese tipo de problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a class=\"anchor\" id=\"second-bullet\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<a class=\"anchor\" id=\"second-bullet\"></a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.16399999999999998, -1, LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       maybe       0.69      0.43      0.53       122\n",
      "         yes       0.62      0.68      0.65       466\n",
      "          no       0.62      0.61      0.62       412\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.64      0.58      0.60      1000\n",
      "weighted avg       0.63      0.62      0.62      1000\n",
      "\n",
      "[[ 53  49  20]\n",
      " [ 13 319 134]\n",
      " [ 11 149 252]]\n",
      "0.624\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       maybe       0.25      0.16      0.20       150\n",
      "         yes       0.48      0.53      0.51       437\n",
      "          no       0.48      0.49      0.49       413\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      1000\n",
      "   macro avg       0.40      0.39      0.40      1000\n",
      "weighted avg       0.45      0.46      0.45      1000\n",
      "\n",
      "[[ 24  69  57]\n",
      " [ 42 232 163]\n",
      " [ 30 179 204]]\n",
      "0.46\n",
      "(0.23999999999999999, 6, LinearSVC(C=64, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.82      0.83      0.82       147\n",
      "     kitchen       0.87      0.83      0.85       183\n",
      "    bathroom       0.83      0.92      0.87       153\n",
      "     bedroom       0.84      0.86      0.85       196\n",
      "      office       0.89      0.81      0.85       158\n",
      "      garden       0.89      0.90      0.89       163\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n",
      "[[122   3   9   5   3   5]\n",
      " [  9 151   6   9   5   3]\n",
      " [  4   1 141   3   2   2]\n",
      " [  4   6   7 169   5   5]\n",
      " [  5   7   6   9 128   3]\n",
      " [  5   5   1   5   1 146]]\n",
      "0.857\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.56      0.65      0.61       153\n",
      "     kitchen       0.66      0.63      0.64       171\n",
      "    bathroom       0.60      0.67      0.64       164\n",
      "     bedroom       0.67      0.60      0.63       187\n",
      "      office       0.62      0.56      0.59       170\n",
      "      garden       0.59      0.59      0.59       155\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.62      0.62      0.62      1000\n",
      "weighted avg       0.62      0.62      0.62      1000\n",
      "\n",
      "[[100  10  15   6  10  12]\n",
      " [ 10 108  14  10  13  16]\n",
      " [ 14   7 110  12  14   7]\n",
      " [ 20  12  16 112  11  16]\n",
      " [ 14  18  15  14  95  14]\n",
      " [ 19   9  12  13  10  92]]\n",
      "0.617\n",
      "(0.255, 6, LinearSVC(C=64, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.80      0.87      0.83       164\n",
      "     kitchen       0.82      0.85      0.83       157\n",
      "    bathroom       0.80      0.79      0.79       182\n",
      "     bedroom       0.85      0.82      0.83       160\n",
      "      office       0.81      0.82      0.81       160\n",
      "      garden       0.88      0.82      0.85       177\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "[[142   6   8   0   6   2]\n",
      " [  5 133   5   5   4   5]\n",
      " [  8  11 143   5  10   5]\n",
      " [  8   5   9 131   5   2]\n",
      " [  9   2   7   5 131   6]\n",
      " [  5   5   6   9   6 146]]\n",
      "0.826\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.54      0.54      0.54       179\n",
      "     kitchen       0.63      0.60      0.61       163\n",
      "    bathroom       0.50      0.65      0.57       152\n",
      "     bedroom       0.61      0.47      0.53       189\n",
      "      office       0.58      0.59      0.58       169\n",
      "      garden       0.58      0.61      0.60       148\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      1000\n",
      "   macro avg       0.58      0.58      0.57      1000\n",
      "weighted avg       0.58      0.57      0.57      1000\n",
      "\n",
      "[[97 15 18 18 18 13]\n",
      " [18 97 13 11 15  9]\n",
      " [11 11 99 11  9 11]\n",
      " [24  8 30 89 18 20]\n",
      " [13 12 22 12 99 11]\n",
      " [17 10 16  4 11 90]]\n",
      "0.571\n",
      "(0.18499999999999994, 12, LinearSVC(C=4096, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.96      0.96      0.96       163\n",
      "     kitchen       0.96      0.95      0.95       158\n",
      "    bathroom       0.99      0.97      0.98       152\n",
      "     bedroom       0.96      0.99      0.97       200\n",
      "      office       0.99      0.97      0.98       163\n",
      "      garden       0.95      0.96      0.95       164\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "[[156   1   1   2   0   3]\n",
      " [  4 150   1   1   0   2]\n",
      " [  1   1 147   0   1   2]\n",
      " [  0   2   0 198   0   0]\n",
      " [  1   1   0   2 158   1]\n",
      " [  0   2   0   4   1 157]]\n",
      "0.966\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.78      0.76      0.77       172\n",
      "     kitchen       0.81      0.75      0.78       183\n",
      "    bathroom       0.83      0.80      0.81       179\n",
      "     bedroom       0.74      0.88      0.80       154\n",
      "      office       0.78      0.78      0.78       153\n",
      "      garden       0.74      0.74      0.74       159\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1000\n",
      "   macro avg       0.78      0.78      0.78      1000\n",
      "weighted avg       0.78      0.78      0.78      1000\n",
      "\n",
      "[[130  10   4  10   9   9]\n",
      " [  8 137   6  11   7  14]\n",
      " [  8   5 143  12   5   6]\n",
      " [  3   3   4 135   5   4]\n",
      " [ 11   3   8   4 119   8]\n",
      " [  6  11   7  11   7 117]]\n",
      "0.781\n",
      "(0.40100000000000002, 6, LinearSVC(C=64, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      school       0.79      0.72      0.75       178\n",
      "      cinema       0.74      0.71      0.72       159\n",
      "     kitchen       0.76      0.80      0.78       173\n",
      "        park       0.78      0.77      0.77       172\n",
      "      office       0.76      0.86      0.81       169\n",
      "     bedroom       0.85      0.83      0.84       149\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1000\n",
      "   macro avg       0.78      0.78      0.78      1000\n",
      "weighted avg       0.78      0.78      0.78      1000\n",
      "\n",
      "[[128  15  13  11   7   4]\n",
      " [ 12 113   6  14   9   5]\n",
      " [  7   6 138   0  14   8]\n",
      " [  9   8  10 132   9   4]\n",
      " [  2   7   7   7 145   1]\n",
      " [  4   4   7   5   6 123]]\n",
      "0.779\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      school       0.34      0.30      0.31       162\n",
      "      cinema       0.38      0.33      0.35       171\n",
      "     kitchen       0.35      0.40      0.37       176\n",
      "        park       0.48      0.43      0.45       177\n",
      "      office       0.37      0.35      0.36       152\n",
      "     bedroom       0.36      0.46      0.40       162\n",
      "\n",
      "   micro avg       0.38      0.38      0.38      1000\n",
      "   macro avg       0.38      0.38      0.38      1000\n",
      "weighted avg       0.38      0.38      0.38      1000\n",
      "\n",
      "[[48 19 30 17 16 32]\n",
      " [29 56 19 20 13 34]\n",
      " [17 24 71 20 19 25]\n",
      " [14 20 32 76 15 20]\n",
      " [20 17 29 11 53 22]\n",
      " [15 10 22 15 26 74]]\n",
      "0.378\n",
      "(0.14700000000000002, -5, LinearSVC(C=0.03125, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        wolf       0.60      0.68      0.64       290\n",
      "         cat       0.62      0.62      0.62       252\n",
      "       sheep       0.62      0.54      0.58       242\n",
      "       mouse       0.67      0.63      0.65       216\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.62      0.62      0.62      1000\n",
      "weighted avg       0.62      0.62      0.62      1000\n",
      "\n",
      "[[197  42  29  22]\n",
      " [ 40 156  32  24]\n",
      " [ 60  29 131  22]\n",
      " [ 32  26  21 137]]\n",
      "0.621\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        wolf       0.36      0.47      0.41       213\n",
      "         cat       0.49      0.56      0.52       239\n",
      "       sheep       0.39      0.36      0.38       207\n",
      "       mouse       0.65      0.48      0.55       341\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      1000\n",
      "   macro avg       0.47      0.47      0.46      1000\n",
      "weighted avg       0.50      0.47      0.48      1000\n",
      "\n",
      "[[101  26  46  40]\n",
      " [ 49 134  35  21]\n",
      " [ 68  38  75  26]\n",
      " [ 66  76  35 164]]\n",
      "0.474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.08500000000000002, 8, LinearSVC(C=256, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       white       0.49      0.60      0.54       226\n",
      "       green       0.55      0.62      0.58       247\n",
      "      yellow       0.68      0.26      0.38       247\n",
      "        gray       0.55      0.68      0.61       280\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1000\n",
      "   macro avg       0.57      0.54      0.53      1000\n",
      "weighted avg       0.57      0.54      0.53      1000\n",
      "\n",
      "[[136  36  12  42]\n",
      " [ 35 153   9  50]\n",
      " [ 59  58  64  66]\n",
      " [ 49  32   9 190]]\n",
      "0.543\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       white       0.43      0.50      0.46       251\n",
      "       green       0.48      0.50      0.49       257\n",
      "      yellow       0.63      0.26      0.37       256\n",
      "        gray       0.41      0.58      0.48       236\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      1000\n",
      "   macro avg       0.49      0.46      0.45      1000\n",
      "weighted avg       0.49      0.46      0.45      1000\n",
      "\n",
      "[[125  51  11  64]\n",
      " [ 55 129  15  58]\n",
      " [ 66  47  66  77]\n",
      " [ 42  44  12 138]]\n",
      "0.458\n",
      "(0.086999999999999966, 6, LinearSVC(C=64, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.58      0.47      0.52       495\n",
      "          no       0.56      0.66      0.61       505\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      1000\n",
      "   macro avg       0.57      0.57      0.56      1000\n",
      "weighted avg       0.57      0.57      0.57      1000\n",
      "\n",
      "[[235 260]\n",
      " [171 334]]\n",
      "0.569\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.46      0.41      0.43       480\n",
      "          no       0.50      0.54      0.52       520\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      1000\n",
      "   macro avg       0.48      0.48      0.48      1000\n",
      "weighted avg       0.48      0.48      0.48      1000\n",
      "\n",
      "[[199 281]\n",
      " [237 283]]\n",
      "0.482\n",
      "(0.11799999999999999, 6, LinearSVC(C=64, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.61      0.66      0.63       495\n",
      "          no       0.64      0.59      0.61       505\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.62      0.62      0.62      1000\n",
      "weighted avg       0.63      0.62      0.62      1000\n",
      "\n",
      "[[326 169]\n",
      " [207 298]]\n",
      "0.624\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.53      0.63      0.58       531\n",
      "          no       0.47      0.36      0.41       469\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      1000\n",
      "   macro avg       0.50      0.50      0.49      1000\n",
      "weighted avg       0.50      0.51      0.50      1000\n",
      "\n",
      "[[336 195]\n",
      " [299 170]]\n",
      "0.506\n",
      "(0.13, -5, LinearSVC(C=0.03125, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         s,w       0.23      0.32      0.27        92\n",
      "         n,n       0.21      0.13      0.16        91\n",
      "         w,n       0.20      0.20      0.20        85\n",
      "         s,e       0.15      0.10      0.12        79\n",
      "         n,e       0.24      0.38      0.30        85\n",
      "         e,n       0.20      0.22      0.21        86\n",
      "         w,s       0.25      0.18      0.21        83\n",
      "         e,e       0.21      0.29      0.24        79\n",
      "         e,s       0.26      0.28      0.27        87\n",
      "         s,s       0.19      0.07      0.10        70\n",
      "         n,w       0.20      0.24      0.22        84\n",
      "         w,w       0.23      0.19      0.21        79\n",
      "\n",
      "   micro avg       0.22      0.22      0.22      1000\n",
      "   macro avg       0.21      0.22      0.21      1000\n",
      "weighted avg       0.22      0.22      0.21      1000\n",
      "\n",
      "[[29  2  8  4  5  6  7  6  6  4  8  7]\n",
      " [10 12  6  2 15  3  6  9  7  3 10  8]\n",
      " [11  4 17  7  9  8  4  8  2  3  9  3]\n",
      " [ 9  3 10  8  8 10  3  8  9  1  5  5]\n",
      " [ 3 12  5  3 32  5  3  9  5  4  2  2]\n",
      " [13  2  4  6  8 19  4  9 11  1  6  3]\n",
      " [ 7  5  7  5  7  8 15  6  5  1  9  8]\n",
      " [ 5  2  6  3 14  8  3 23  5  1  6  3]\n",
      " [ 6  8  7  5  3  7  2  8 24  1 12  4]\n",
      " [14  3  9  4 10  4  4  7  3  5  3  4]\n",
      " [ 8  3  3  3 15  5  5 10  7  1 20  4]\n",
      " [10  1  4  5  5 10  3  8  8  2  8 15]]\n",
      "0.219\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         s,w       0.10      0.15      0.12        81\n",
      "         n,n       0.06      0.03      0.04        88\n",
      "         w,n       0.08      0.09      0.09        79\n",
      "         s,e       0.16      0.08      0.11        85\n",
      "         n,e       0.13      0.17      0.15        92\n",
      "         e,n       0.08      0.08      0.08        92\n",
      "         w,s       0.11      0.08      0.10        83\n",
      "         e,e       0.09      0.14      0.11        71\n",
      "         e,s       0.04      0.05      0.05        93\n",
      "         s,s       0.04      0.01      0.02        80\n",
      "         n,w       0.07      0.08      0.08        90\n",
      "         w,w       0.08      0.11      0.09        66\n",
      "\n",
      "   micro avg       0.09      0.09      0.09      1000\n",
      "   macro avg       0.09      0.09      0.09      1000\n",
      "weighted avg       0.09      0.09      0.09      1000\n",
      "\n",
      "[[12  6  9  4 11  6  5  1  8  2  3 14]\n",
      " [18  3  7  3 19  9  3  8  6  1  5  6]\n",
      " [14  4  7  5  5  5  7  3 11  3 10  5]\n",
      " [ 7  7  2  7  7  6  7  7 16  3  9  7]\n",
      " [ 7  2  9  4 16  9  7 11  9  1  9  8]\n",
      " [ 7  4 12  1  8  7  7 13 10  3  8 12]\n",
      " [13  2  8  1  9  6  7 11  9  3 10  4]\n",
      " [ 5  6  3  5 12  2  6 10  8  2  8  4]\n",
      " [13  4  7  2 17 10  2 14  5  3  9  7]\n",
      " [ 6  7  5  5 10 13  4  9  8  1  5  7]\n",
      " [11  2  9  5  8  7  8 14 12  2  7  5]\n",
      " [ 7  3  6  1  5  4  1 11 10  0 11  7]]\n",
      "0.089\n",
      "(0.24799999999999994, -1, LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.67      0.63      0.65       154\n",
      "     kitchen       0.71      0.65      0.68       155\n",
      "    bathroom       0.68      0.67      0.67       177\n",
      "     bedroom       0.71      0.71      0.71       175\n",
      "      office       0.71      0.74      0.72       173\n",
      "      garden       0.70      0.77      0.73       166\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1000\n",
      "   macro avg       0.70      0.69      0.69      1000\n",
      "weighted avg       0.70      0.70      0.70      1000\n",
      "\n",
      "[[ 97   8  12  20   5  12]\n",
      " [ 11 101  13   7  14   9]\n",
      " [ 10   8 118   9  16  16]\n",
      " [  9  10  11 125  11   9]\n",
      " [  7  10  10   9 128   9]\n",
      " [ 11   5  10   6   7 127]]\n",
      "0.696\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.36      0.35      0.35       149\n",
      "     kitchen       0.47      0.34      0.39       171\n",
      "    bathroom       0.48      0.52      0.50       187\n",
      "     bedroom       0.39      0.45      0.42       154\n",
      "      office       0.48      0.54      0.50       157\n",
      "      garden       0.50      0.48      0.49       182\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1000\n",
      "   macro avg       0.45      0.45      0.44      1000\n",
      "weighted avg       0.45      0.45      0.45      1000\n",
      "\n",
      "[[52 23 19 25 15 15]\n",
      " [23 58 28 23 23 16]\n",
      " [14 12 97 19 17 28]\n",
      " [17 12 20 70 20 15]\n",
      " [16  7 19 18 84 13]\n",
      " [23 12 20 23 17 87]]\n",
      "0.448\n",
      "(0.18499999999999994, 9, LinearSVC(C=512, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       tired       1.00      1.00      1.00        91\n",
      "     thirsty       0.99      0.99      0.99       164\n",
      "     kitchen       1.00      1.00      1.00        98\n",
      "      hungry       0.99      0.99      0.99       151\n",
      "     bedroom       1.00      1.00      1.00       186\n",
      "       bored       1.00      1.00      1.00       158\n",
      "      garden       1.00      0.99      1.00       152\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[ 91   0   0   0   0   0   0]\n",
      " [  0 163   0   1   0   0   0]\n",
      " [  0   0  98   0   0   0   0]\n",
      " [  0   1   0 150   0   0   0]\n",
      " [  0   0   0   0 186   0   0]\n",
      " [  0   0   0   0   0 158   0]\n",
      " [  0   0   0   1   0   0 151]]\n",
      "0.997\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       tired       0.79      0.76      0.77        97\n",
      "     thirsty       0.97      0.84      0.90       159\n",
      "     kitchen       0.66      0.78      0.72        94\n",
      "      hungry       0.73      0.75      0.74       157\n",
      "     bedroom       0.85      0.87      0.86       180\n",
      "       bored       0.71      0.76      0.73       152\n",
      "      garden       0.95      0.89      0.92       161\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n",
      "[[ 74   0  11   0  11   1   0]\n",
      " [  1 133   7  11   2   5   0]\n",
      " [  5   0  73   1  13   0   2]\n",
      " [  0   1   1 117   0  37   1]\n",
      " [  8   2  14   0 156   0   0]\n",
      " [  2   1   1  26   1 116   5]\n",
      " [  4   0   3   6   0   5 143]]\n",
      "0.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.78900000000000003, 8, LinearSVC(C=256, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       1.00      1.00      1.00       145\n",
      "     kitchen       1.00      1.00      1.00       158\n",
      "    bathroom       1.00      1.00      1.00       210\n",
      "     bedroom       1.00      1.00      1.00       138\n",
      "      office       1.00      1.00      1.00       147\n",
      "      garden       1.00      1.00      1.00       202\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[145   0   0   0   0   0]\n",
      " [  0 158   0   0   0   0]\n",
      " [  0   0 210   0   0   0]\n",
      " [  0   0   0 138   0   0]\n",
      " [  0   0   0   0 147   0]\n",
      " [  0   0   0   0   0 202]]\n",
      "1.0\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.28      0.22      0.24       175\n",
      "     kitchen       0.20      0.21      0.20       167\n",
      "    bathroom       0.27      0.29      0.28       187\n",
      "     bedroom       0.21      0.17      0.19       160\n",
      "      office       0.15      0.12      0.13       165\n",
      "      garden       0.17      0.24      0.20       146\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      1000\n",
      "   macro avg       0.21      0.21      0.21      1000\n",
      "weighted avg       0.21      0.21      0.21      1000\n",
      "\n",
      "[[38 35 30 15 22 35]\n",
      " [19 35 34 22 24 33]\n",
      " [18 21 55 26 35 32]\n",
      " [27 16 28 28 16 45]\n",
      " [26 38 31 24 20 26]\n",
      " [10 33 28 20 20 35]]\n",
      "0.211\n",
      "(0.79600000000000004, -5, LinearSVC(C=0.03125, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.98      0.98      0.98       198\n",
      "     kitchen       0.99      1.00      0.99       144\n",
      "    bathroom       0.99      0.98      0.99       171\n",
      "     bedroom       0.99      0.98      0.99       183\n",
      "      office       0.99      0.99      0.99       146\n",
      "      garden       0.99      0.99      0.99       158\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[195   0   1   1   1   0]\n",
      " [  0 144   0   0   0   0]\n",
      " [  1   1 168   0   1   0]\n",
      " [  2   1   0 180   0   0]\n",
      " [  1   0   0   0 144   1]\n",
      " [  0   0   0   1   0 157]]\n",
      "0.988\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.23      0.31      0.26       185\n",
      "     kitchen       0.15      0.19      0.17       154\n",
      "    bathroom       0.26      0.19      0.22       215\n",
      "     bedroom       0.26      0.24      0.25       167\n",
      "      office       0.08      0.07      0.07       146\n",
      "      garden       0.11      0.10      0.10       133\n",
      "\n",
      "   micro avg       0.19      0.19      0.19      1000\n",
      "   macro avg       0.18      0.18      0.18      1000\n",
      "weighted avg       0.19      0.19      0.19      1000\n",
      "\n",
      "[[58 39 35 17 22 14]\n",
      " [46 30 22 23 16 17]\n",
      " [51 41 41 29 25 28]\n",
      " [28 24 19 40 23 33]\n",
      " [35 40 24 26 10 11]\n",
      " [36 23 17 19 25 13]]\n",
      "0.192\n",
      "(0.088999999999999968, 7, LinearSVC(C=128, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.74      0.78      0.76       159\n",
      "     kitchen       0.78      0.66      0.71       160\n",
      "    bathroom       0.70      0.94      0.80       162\n",
      "     bedroom       0.82      0.66      0.73       169\n",
      "      office       0.78      0.85      0.81       180\n",
      "      garden       0.84      0.74      0.78       170\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1000\n",
      "   macro avg       0.78      0.77      0.77      1000\n",
      "weighted avg       0.78      0.77      0.77      1000\n",
      "\n",
      "[[124   8   6   7   9   5]\n",
      " [ 15 105  21   5   9   5]\n",
      " [  2   0 152   1   6   1]\n",
      " [ 13  10  15 111  14   6]\n",
      " [  7   1  10   2 153   7]\n",
      " [  7  10  14   9   5 125]]\n",
      "0.77\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hallway       0.70      0.69      0.69       177\n",
      "     kitchen       0.70      0.63      0.66       156\n",
      "    bathroom       0.62      0.91      0.74       167\n",
      "     bedroom       0.74      0.57      0.64       176\n",
      "      office       0.67      0.74      0.71       171\n",
      "      garden       0.70      0.54      0.61       153\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1000\n",
      "   macro avg       0.69      0.68      0.68      1000\n",
      "weighted avg       0.69      0.68      0.68      1000\n",
      "\n",
      "[[122   5  16  10  17   7]\n",
      " [ 17  98  22   5   7   7]\n",
      " [  2   0 152   2   9   2]\n",
      " [ 12  15  19 100  21   9]\n",
      " [  8   5  13   8 127  10]\n",
      " [ 14  17  22  10   8  82]]\n",
      "0.681\n",
      "(0.61299999999999999, 6, LinearSVC(C=64, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mary       1.00      1.00      1.00       151\n",
      "        milk       1.00      1.00      1.00       167\n",
      "        Jeff       1.00      1.00      1.00       144\n",
      "        Fred       1.00      1.00      1.00       171\n",
      "        Bill       1.00      1.00      1.00       136\n",
      "       apple       1.00      1.00      1.00       136\n",
      "    football       1.00      1.00      1.00        95\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[151   0   0   0   0   0   0]\n",
      " [  0 167   0   0   0   0   0]\n",
      " [  0   0 144   0   0   0   0]\n",
      " [  0   0   0 171   0   0   0]\n",
      " [  0   0   0   0 136   0   0]\n",
      " [  0   0   0   0   0 136   0]\n",
      " [  0   0   0   0   0   0  95]]\n",
      "1.0\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mary       0.28      0.28      0.28       164\n",
      "        milk       0.37      0.30      0.33       188\n",
      "        Jeff       0.22      0.31      0.25       129\n",
      "        Fred       0.36      0.40      0.38       189\n",
      "        Bill       0.66      0.53      0.59       137\n",
      "       apple       0.49      0.56      0.52        95\n",
      "    football       0.61      0.44      0.51        98\n",
      "\n",
      "   micro avg       0.39      0.39      0.39      1000\n",
      "   macro avg       0.43      0.40      0.41      1000\n",
      "weighted avg       0.41      0.39      0.39      1000\n",
      "\n",
      "[[46 28 39 49  1  0  1]\n",
      " [48 57 44 37  2  0  0]\n",
      " [27 30 40 29  2  1  0]\n",
      " [29 35 48 75  1  1  0]\n",
      " [ 2  1  8  4 73 36 13]\n",
      " [ 1  0  1  8 19 53 13]\n",
      " [ 9  4  5  8 12 17 43]]\n",
      "0.387\n",
      "(0.18899999999999995, -1, LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.71      0.69      0.70       492\n",
      "          no       0.71      0.73      0.72       508\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1000\n",
      "   macro avg       0.71      0.71      0.71      1000\n",
      "weighted avg       0.71      0.71      0.71      1000\n",
      "\n",
      "[[340 152]\n",
      " [139 369]]\n",
      "0.709\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.53      0.48      0.50       503\n",
      "          no       0.52      0.56      0.54       497\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1000\n",
      "   macro avg       0.52      0.52      0.52      1000\n",
      "weighted avg       0.52      0.52      0.52      1000\n",
      "\n",
      "[[241 262]\n",
      " [218 279]]\n",
      "0.52\n",
      "(0.36599999999999999, 11, LinearSVC(C=2048, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       three       0.95      0.99      0.97       468\n",
      "         two       0.98      0.94      0.96       488\n",
      "         one       0.50      1.00      0.67         1\n",
      "        none       0.91      0.93      0.92        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1000\n",
      "   macro avg       0.83      0.96      0.88      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n",
      "[[461   7   0   0]\n",
      " [ 24 459   1   4]\n",
      " [  0   0   1   0]\n",
      " [  2   1   0  40]]\n",
      "0.961\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       three       0.65      0.59      0.62       468\n",
      "         two       0.62      0.64      0.63       488\n",
      "         one       0.00      0.00      0.00         2\n",
      "        none       0.23      0.19      0.21        42\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      1000\n",
      "   macro avg       0.37      0.35      0.36      1000\n",
      "weighted avg       0.62      0.59      0.60      1000\n",
      "\n",
      "[[276 163  20   9]\n",
      " [143 311  16  18]\n",
      " [  0   2   0   0]\n",
      " [  8  23   3   8]]\n",
      "0.595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.56999999999999995, 7, LinearSVC(C=128, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "apple,milk,football       0.92      0.97      0.95       194\n",
      "     apple,football       1.00      1.00      1.00        10\n",
      "      milk,football       0.67      0.67      0.67         3\n",
      "            nothing       1.00      1.00      1.00        22\n",
      "     football,apple       1.00      1.00      1.00         2\n",
      "football,apple,milk       0.96      0.99      0.98       188\n",
      "milk,football,apple       1.00      0.92      0.96        12\n",
      "apple,football,milk       0.90      1.00      0.95         9\n",
      "         apple,milk       0.99      0.94      0.97       198\n",
      "               milk       1.00      0.83      0.91         6\n",
      "         milk,apple       1.00      1.00      1.00        11\n",
      "              apple       1.00      1.00      1.00         1\n",
      "           football       0.99      0.97      0.98       344\n",
      "\n",
      "          micro avg       0.97      0.97      0.97      1000\n",
      "          macro avg       0.96      0.95      0.95      1000\n",
      "       weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "[[189   0   0   0   0   2   0   0   1   0   0   0   2]\n",
      " [  0  10   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   1   0   0   0   0   0   0   0]\n",
      " [  0   0   0  22   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0 186   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0  11   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   9   0   0   0   0   0]\n",
      " [  9   0   0   0   0   1   0   1 187   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   5   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  11   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0]\n",
      " [  6   0   1   0   0   3   0   0   0   0   0   0 334]]\n",
      "0.969\n",
      "Evaluar sobre el split de testing\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "apple,milk,football       0.39      0.39      0.39       204\n",
      "     apple,football       0.00      0.00      0.00        11\n",
      "      milk,football       0.00      0.00      0.00         1\n",
      "            nothing       0.04      0.10      0.06        10\n",
      "     football,apple       0.00      0.00      0.00         0\n",
      "football,apple,milk       0.45      0.46      0.45       186\n",
      "milk,football,apple       0.06      0.06      0.06        18\n",
      "apple,football,milk       0.00      0.00      0.00         7\n",
      "         apple,milk       0.41      0.47      0.44       207\n",
      "               milk       0.00      0.00      0.00         9\n",
      "         milk,apple       0.00      0.00      0.00        10\n",
      "              apple       0.00      0.00      0.00         0\n",
      "           football       0.61      0.40      0.48       336\n",
      "\n",
      "          micro avg       0.40      0.40      0.40       999\n",
      "          macro avg       0.15      0.14      0.14       999\n",
      "       weighted avg       0.46      0.40      0.42       999\n",
      "\n",
      "[[ 80   7  11   4   2  18   6   0   4  29   6   2   1  34]\n",
      " [  3   0   0   1   0   6   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  1   0   0   1   0   2   0   0   0   5   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 27   5   5   3   0  85   3   0   5  30   0   2   1  20]\n",
      " [  3   1   2   1   0   3   1   0   0   1   0   2   0   4]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   2   0   0   0   2   2   0   0   0]\n",
      " [ 29   1   2   5   0  31   3   0   4  97   1   5   3  26]\n",
      " [  2   0   1   0   0   0   0   0   0   6   0   0   0   0]\n",
      " [  0   1   0   1   0   2   0   0   0   6   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 59   1  15   9   1  41   3   0   6  58   2   4   2 135]]\n",
      "0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1537: UserWarning: labels size, 13, does not match size of target_names, 14\n",
      "  .format(len(labels), len(target_names))\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1537: UserWarning: labels size, 13, does not match size of target_names, 14\n",
      "  .format(len(labels), len(target_names))\n",
      "c:\\users\\luism\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.15100000000000002, 8, LinearSVC(C=256, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))\n",
      "Evaluar sobre el split de training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.80      0.60      0.69       633\n",
      "          no       0.52      0.74      0.61       367\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      1000\n",
      "   macro avg       0.66      0.67      0.65      1000\n",
      "weighted avg       0.69      0.65      0.66      1000\n",
      "\n",
      "[[381 252]\n",
      " [ 97 270]]\n",
      "0.651\n",
      "Evaluar sobre el split de testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.65      0.47      0.55       638\n",
      "          no       0.37      0.54      0.44       362\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      1000\n",
      "   macro avg       0.51      0.51      0.49      1000\n",
      "weighted avg       0.55      0.50      0.51      1000\n",
      "\n",
      "[[303 335]\n",
      " [165 197]]\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" cellpadding=\"3\" cellspacing=\"0\"  style=\"border:black; border-collapse:collapse;\"><tr><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>Task</b></td><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>C</b></td><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>Train&nbsp;Accuracy</b></td><td  style=\"background-color:LightGray;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\"><b>Test&nbsp;Accuracy</b></td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">1</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5000</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6960</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4480</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">2</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">256</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">1.0000</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2110</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">3</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0312</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.9880</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.1920</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">4</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">128</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.7700</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6810</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">5</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">64</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">1.0000</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.3870</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">6</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5000</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.7090</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5200</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">7</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">2048</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.9610</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5950</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">8</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">128</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.9690</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.3990</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">9</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">256</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6510</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5000</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">10</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5000</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6240</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4600</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">11</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">64</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.8570</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6170</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">12</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">64</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.8260</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5710</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">13</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">4096</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.9660</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.7810</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">14</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">64</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.7790</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.3780</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">15</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0312</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6210</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4740</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">16</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">256</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5430</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4580</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">17</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">64</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5690</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.4820</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">18</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">64</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.6240</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5060</td></tr><tr><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">19</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0312</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2190</td><td  style=\"background-color:Ivory;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0890</td></tr><tr><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">20</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">512</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.9970</td><td  style=\"background-color:AliceBlue;border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.8120</td></tr></table>"
      ],
      "text/plain": [
       "<ipy_table.ipy_table.IpyTable at 0x106f0d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction=main_svm()\n",
    "lista=[[i,diction[i][\"C\"],diction[i][\"train_accuracy\"],diction[i][\"test_accuracy\"]] for i in sorted(diction.keys())]\n",
    "make_table([[\"Task\",\"C\",\"Train Accuracy\",\"Test Accuracy\"]]+lista)\n",
    "apply_theme('basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como podemos ver en las tablas presentadas en el punto anterior y mis comentarios sobre c, si el modelo tiene una precicion significativamente menor en el set de entrenamiento que en el set de test, entonces esta sobre-ajustado.\n",
    "* En promedio, los resultados que obtuve indican que esta efectivamente sobreajustando mi modelo. Tiene una baja capacidad de generalizacion.\n",
    "* Las categorías que obtienen peor rendimiento son $19,3,2$ en ese orden. \n",
    "* El modelo SVM que tenemos con un kernel lineal, se ve afectado cuando aumentamos el numero de supporting-facts. Se puede ver que el rendimiento disminuye desde el task $1$ (One-supporting-fact) al task 3 (Three-supporting-facts).\n",
    "* El task $19$ tuvo el peor rendimiento de todos, lo cual nos dice que este tipo de SVM no es bueno para problemas de búsqueda. Opino que un kernel no lineal puede mejorar el rendimiento.\n",
    "* La categoria con mejor rendimiento fue la $20$. Una razon por la cual el modelo SVM obtuvo buenos resultados es porque el dominio es bastante acotado con los ejemplos de entrenamiento que tenemos. Solo hay 2 motivaciones de el agente que obtiene malos resultados en ese task que son 'bored' y 'tired'. Esto tiene sentido porque son difíciles de distinguir a primera mano y mas que todo con poca informacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a class=\"anchor\" id=\"third-bullet\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<a class=\"anchor\" id=\"third-bullet\"></a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Resultados Comparativos:\n",
    "* Facilidad de uso: SVM fue muy simple de usar y se puede dar una interpretacion concreta a los datos '\n",
    "* Tiempo de proceso: SVM fue considerablemente mas rapido, los 20 Tasks los pude ejecutar junto con la optimizacion de parametros en 10 minutos. Mientras que NN tuvo que correr en 5 horas para poder ejecutarse. \n",
    "* Exactitud de clasificacion: NN tuvo pero exactitud en promedio que SVM pero tuvo menos overfitting que SVM.\n",
    "* Los errores mas frecuentes de los modelos y al realizar los tests fueron con respecto a que los modelos no convergian dados los criterios de termino \n",
    "* Ademas,tuve problemas con las dimensiones de el Task 8 porque habian respuestas en el set de test que no estaban en el set de entrenamiento, por lo tanto tuve que acotadar el dominio de clases con respecto al set de entrenamiento.\n",
    "\n",
    "* Una da las muchas mejoras que se pueden hacer al modelo es que se puede dar un peso a las clases, especialemente para SVM, porque el numero datos por clases no es el mismo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a class=\"anchor\" id=\"fourth-bullet\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<a class=\"anchor\" id=\"fourth-bullet\"></a>'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
